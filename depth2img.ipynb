{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ibocgBv8tjQ"
      },
      "source": [
        "# Text-guided depth-to-image generation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_kdQw1C8tjd"
      },
      "source": [
        "The [StableDiffusionDepth2ImgPipeline](https://huggingface.co/docs/diffusers/main/en/api/pipelines/stable_diffusion/depth2img#diffusers.StableDiffusionDepth2ImgPipeline) lets you pass a text prompt and an initial image to condition the generation of new images. In addition, you can also pass a `depth_map` to preserve the image structure. If no `depth_map` is provided, the pipeline automatically predicts the depth via an integrated [depth-estimation model](https://github.com/isl-org/MiDaS).\n",
        "\n",
        "Start by creating an instance of the [StableDiffusionDepth2ImgPipeline](https://huggingface.co/docs/diffusers/main/en/api/pipelines/stable_diffusion/depth2img#diffusers.StableDiffusionDepth2ImgPipeline):"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install diffusers transformers ftfy accelerate"
      ],
      "metadata": {
        "id": "gfVvGOzb8wSD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pVy8mGTb8tjg"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import requests\n",
        "from PIL import Image\n",
        "\n",
        "from diffusers import StableDiffusionDepth2ImgPipeline\n",
        "\n",
        "pipe = StableDiffusionDepth2ImgPipeline.from_pretrained(\n",
        "    \"stabilityai/stable-diffusion-2-depth\",\n",
        "    torch_dtype=torch.float16,\n",
        ").to(\"cuda\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GzxHA6-r8tjl"
      },
      "source": [
        "Now pass your prompt to the pipeline. You can also pass a `negative_prompt` to prevent certain words from guiding how an image is generated:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xxNcsdEB8tjn"
      },
      "outputs": [],
      "source": [
        "url = \"http://images.cocodataset.org/val2017/000000039769.jpg\"\n",
        "init_image = Image.open(requests.get(url, stream=True).raw)\n",
        "prompt = \"two tigers\"\n",
        "n_prompt = \"bad, deformed, ugly, bad anatomy\"\n",
        "image = pipe(prompt=prompt, image=init_image, negative_prompt=n_prompt, strength=0.7).images[0]\n",
        "image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-3rEE4O18tjp"
      },
      "source": [
        "| Input                                                                           | Output                                                                                                                                |\n",
        "|---------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------------------|\n",
        "| <img src=\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/coco-cats.png\" width=\"500\"/> | <img src=\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/depth2img-tigers.png\" width=\"500\"/> |\n",
        "\n",
        "Play around with the Spaces below and see if you notice a difference between generated images with and without a depth map!\n",
        "\n",
        "<iframe\n",
        "\tsrc=\"https://radames-stable-diffusion-depth2img.hf.space\"\n",
        "\tframeborder=\"0\"\n",
        "\twidth=\"850\"\n",
        "\theight=\"500\"\n",
        "></iframe>"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}